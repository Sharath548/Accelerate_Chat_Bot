# ğŸ¤– Accelerate Chat Bot

A fully local, open-source AI assistant that can:
- ğŸ“‚ Watch a folder and index any uploaded documents
- ğŸ§  Build a semantic knowledge base using embeddings + FAISS
- ğŸ’¬ Let you ask natural language questions via a clean Streamlit UI
- ğŸ§ª Generate test cases or summaries using a local LLM (like Mistral via Ollama)
- ğŸ§© Understand PDFs, Word docs, images (OCR), plain text, and code

---

## ğŸš€ Features

- âœ… Local only â€” no internet or API needed
- ğŸ“ File types: `.pdf`, `.docx`, `.txt`, `.jpg`, `.png`, `.py`, `.json`
- ğŸ¤– Works with Ollama + open LLMs (Mistral, LLaMA3, Gemma)
- ğŸ§  Uses FAISS for fast vector-based search
- ğŸ’¬ Built-in Streamlit chat UI

---

## ğŸ§° Tech Stack

| Component        | Tool                      |
|------------------|---------------------------|
| File Watcher     | `watchdog`                |
| Text Extraction  | `PyMuPDF`, `python-docx`, `pytesseract` |
| Embeddings       | `sentence-transformers` (MiniLM) |
| Vector DB        | `FAISS`                   |
| LLM Runtime      | `Ollama` + `mistral`      |
| UI               | `Streamlit`               |

---

## ğŸ“¦ Installation

### 1. Clone the Repo

```bash
git clone https://github.com/Sharath548/Accelerate_Chat_Bot.git
cd Accelerate_Chat_Bot
2. Create a Virtual Environment
bash
Copy
Edit
python -m venv venv
Activate it:

On Windows:

bash
Copy
Edit
venv\Scripts\activate
On macOS/Linux:

bash
Copy
Edit
source venv/bin/activate
3. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸ§  Ollama Setup (Local LLM)
1. Install Ollama
Download and install from https://ollama.com/download

2. Pull a model
For example:

bash
Copy
Edit
ollama pull mistral
ğŸ“‚ How to Use
1. Start File Watcher (Indexing)
bash
Copy
Edit
python ai_bot/main.py
Drop files into the input_files/ folder â€” they'll be automatically parsed, embedded, and saved.

2. Start the Chatbot UI
bash
Copy
Edit
streamlit run ai_bot/ui/chat_ui.py
Go to http://localhost:8501, and start chatting with your bot!

Example questions:

"Generate test cases for bronze enrollment"

"What is this diagram about?"

"List all steps in the refund flow"

ğŸ—ƒ Project Structure
bash
Copy
Edit
Accelerate_Chat_Bot/
â”œâ”€â”€ ai_bot/
â”‚   â”œâ”€â”€ watcher/         # File watcher for new documents
â”‚   â”œâ”€â”€ indexer/         # Parser, embedder, vector store
â”‚   â”œâ”€â”€ retriever/       # Query engine for semantic search
â”‚   â”œâ”€â”€ llm/             # Ollama interface
â”‚   â””â”€â”€ ui/              # Streamlit UI
â”œâ”€â”€ input_files/         # Folder to drop files into
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â””â”€â”€ README.md
âš ï¸ Troubleshooting
"Ollama timed out"
â†’ Increase timeout in ollama_interface.py and check if Ollama is running

"No documents found"
â†’ Make sure files are placed in input_files/ before asking questions

OCR issues?
â†’ Install Tesseract OCR and add it to your PATH

ğŸ™Œ Credits
Developed by Sharath Chandra Reddy
Powered by Ollama + open-source LLMs + Python

ğŸ” Privacy & Security
100% offline

No data leaves your system

Ideal for enterprise environments with sensitive data

ğŸ Future Plans
Flowchart â†’ logic parser

Export test cases to .feature files

Advanced RAG tuning and multi-file relationships

Live context preview in UI